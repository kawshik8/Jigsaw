2019-11-25 19:19:12,034 [MainThread  ] Experiment Exp-1
2019-11-25 19:19:12,035 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:19:12,035 [MainThread  ] Start creating tasks
2019-11-25 19:19:12,035 [MainThread  ] Start loading data
2019-11-25 19:19:12,035 [MainThread  ] Loading cifar10_un data
2019-11-25 19:19:19,352 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:19:21,641 [MainThread  ] Start creating models
2019-11-25 19:19:25,188 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:19:25,189 [MainThread  ] Start training cifar10_un
2019-11-25 19:23:20,213 [MainThread  ] Experiment Exp-1
2019-11-25 19:23:20,222 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:23:20,222 [MainThread  ] Start creating tasks
2019-11-25 19:23:20,222 [MainThread  ] Start loading data
2019-11-25 19:23:20,222 [MainThread  ] Loading cifar10_un data
2019-11-25 19:23:27,788 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:23:30,035 [MainThread  ] Start creating models
2019-11-25 19:23:33,536 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:23:33,537 [MainThread  ] Start training cifar10_un
2019-11-25 19:25:34,775 [MainThread  ] Experiment Exp-1
2019-11-25 19:25:34,776 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:25:34,776 [MainThread  ] Start creating tasks
2019-11-25 19:25:34,777 [MainThread  ] Start loading data
2019-11-25 19:25:34,777 [MainThread  ] Loading cifar10_un data
2019-11-25 19:25:42,173 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:25:44,391 [MainThread  ] Start creating models
2019-11-25 19:25:47,918 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:25:47,918 [MainThread  ] Start training cifar10_un
2019-11-25 19:26:59,150 [MainThread  ] Experiment Exp-1
2019-11-25 19:26:59,159 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:26:59,159 [MainThread  ] Start creating tasks
2019-11-25 19:26:59,159 [MainThread  ] Start loading data
2019-11-25 19:26:59,159 [MainThread  ] Loading cifar10_un data
2019-11-25 19:27:06,419 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:27:08,681 [MainThread  ] Start creating models
2019-11-25 19:27:12,219 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:27:12,220 [MainThread  ] Start training cifar10_un
2019-11-25 19:30:36,279 [MainThread  ] Experiment Exp-1
2019-11-25 19:30:36,280 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:30:36,280 [MainThread  ] Start creating tasks
2019-11-25 19:30:36,280 [MainThread  ] Start loading data
2019-11-25 19:30:36,281 [MainThread  ] Loading cifar10_un data
2019-11-25 19:30:43,813 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:30:46,020 [MainThread  ] Start creating models
2019-11-25 19:30:49,559 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:30:49,559 [MainThread  ] Start training cifar10_un
2019-11-25 19:31:27,244 [MainThread  ] Experiment Exp-1
2019-11-25 19:31:27,245 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:31:27,245 [MainThread  ] Start creating tasks
2019-11-25 19:31:27,245 [MainThread  ] Start loading data
2019-11-25 19:31:27,245 [MainThread  ] Loading cifar10_un data
2019-11-25 19:31:34,516 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:31:36,826 [MainThread  ] Start creating models
2019-11-25 19:31:40,396 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:31:40,396 [MainThread  ] Start training cifar10_un
2019-11-25 19:32:05,790 [MainThread  ] Experiment Exp-1
2019-11-25 19:32:05,790 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:32:05,790 [MainThread  ] Start creating tasks
2019-11-25 19:32:05,791 [MainThread  ] Start loading data
2019-11-25 19:32:05,791 [MainThread  ] Loading cifar10_un data
2019-11-25 19:32:13,041 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:32:15,256 [MainThread  ] Start creating models
2019-11-25 19:32:18,819 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:32:18,819 [MainThread  ] Start training cifar10_un
2019-11-25 19:33:04,497 [MainThread  ] Experiment Exp-1
2019-11-25 19:33:04,506 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:33:04,506 [MainThread  ] Start creating tasks
2019-11-25 19:33:04,506 [MainThread  ] Start loading data
2019-11-25 19:33:04,507 [MainThread  ] Loading cifar10_un data
2019-11-25 19:33:11,827 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:33:14,047 [MainThread  ] Start creating models
2019-11-25 19:33:17,629 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:33:17,630 [MainThread  ] Start training cifar10_un
2019-11-25 19:35:11,599 [MainThread  ] Experiment Exp-1
2019-11-25 19:35:11,621 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:35:11,621 [MainThread  ] Start creating tasks
2019-11-25 19:35:11,621 [MainThread  ] Start loading data
2019-11-25 19:35:11,621 [MainThread  ] Loading cifar10_un data
2019-11-25 19:35:18,858 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:35:21,213 [MainThread  ] Start creating models
2019-11-25 19:35:24,876 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:35:24,876 [MainThread  ] Start training cifar10_un
2019-11-25 19:36:50,996 [MainThread  ] Experiment Exp-1
2019-11-25 19:36:50,997 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:36:50,997 [MainThread  ] Start creating tasks
2019-11-25 19:36:50,997 [MainThread  ] Start loading data
2019-11-25 19:36:50,997 [MainThread  ] Loading cifar10_un data
2019-11-25 19:36:58,420 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:37:00,620 [MainThread  ] Start creating models
2019-11-25 19:37:04,235 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:37:04,235 [MainThread  ] Start training cifar10_un
2019-11-25 19:42:42,295 [MainThread  ] Experiment Exp-1
2019-11-25 19:42:42,304 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=10, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:42:42,304 [MainThread  ] Start creating tasks
2019-11-25 19:42:42,304 [MainThread  ] Start loading data
2019-11-25 19:42:42,304 [MainThread  ] Loading cifar10_un data
2019-11-25 19:42:49,676 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:42:51,994 [MainThread  ] Start creating models
2019-11-25 19:42:55,664 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:42:55,664 [MainThread  ] Start training cifar10_un
2019-11-25 19:44:06,177 [MainThread  ] Experiment Exp-1
2019-11-25 19:44:06,178 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=10, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:44:06,178 [MainThread  ] Start creating tasks
2019-11-25 19:44:06,179 [MainThread  ] Start loading data
2019-11-25 19:44:06,179 [MainThread  ] Loading cifar10_un data
2019-11-25 19:44:13,561 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:44:15,778 [MainThread  ] Start creating models
2019-11-25 19:44:19,404 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:44:19,405 [MainThread  ] Start training cifar10_un
2019-11-25 19:44:44,652 [MainThread  ] train batch 10 / 1562 (iter 10), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:45:06,852 [MainThread  ] train batch 20 / 1562 (iter 20), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:45:29,071 [MainThread  ] train batch 30 / 1562 (iter 30), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:45:51,269 [MainThread  ] train batch 40 / 1562 (iter 40), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:46:13,456 [MainThread  ] train batch 50 / 1562 (iter 50), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:46:35,667 [MainThread  ] train batch 60 / 1562 (iter 60), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:46:57,890 [MainThread  ] train batch 70 / 1562 (iter 70), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 19:57:06,977 [MainThread  ] Experiment Exp-1
2019-11-25 19:57:07,040 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 19:57:07,040 [MainThread  ] Start creating tasks
2019-11-25 19:57:07,040 [MainThread  ] Start loading data
2019-11-25 19:57:07,040 [MainThread  ] Loading cifar10_un data
2019-11-25 19:57:15,614 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 19:57:17,883 [MainThread  ] Start creating models
2019-11-25 19:57:22,326 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 19:57:22,326 [MainThread  ] Start training cifar10_un
2019-11-25 20:06:43,619 [MainThread  ] train batch 250 / 1562 (iter 250), current average result {'loss': tensor(27.2472, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 20:16:01,086 [MainThread  ] train batch 500 / 1562 (iter 500), current average result {'loss': tensor(27.2471, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 20:25:20,599 [MainThread  ] train batch 750 / 1562 (iter 750), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 20:34:40,386 [MainThread  ] train batch 1000 / 1562 (iter 1000), current average result {'loss': tensor(27.2475, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 20:43:59,069 [MainThread  ] train batch 1250 / 1562 (iter 1250), current average result {'loss': tensor(27.2475, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 20:53:18,577 [MainThread  ] train batch 1500 / 1562 (iter 1500), current average result {'loss': tensor(27.2473, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 21:02:44,028 [MainThread  ] train batch 188 / 1562 (iter 1750), current average result {'loss': tensor(27.2471, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 21:12:02,849 [MainThread  ] train batch 438 / 1562 (iter 2000), current average result {'loss': tensor(27.2470, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 21:21:28,535 [MainThread  ] train batch 688 / 1562 (iter 2250), current average result {'loss': tensor(27.2469, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 21:30:48,816 [MainThread  ] train batch 938 / 1562 (iter 2500), current average result {'loss': tensor(27.2470, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 21:40:10,722 [MainThread  ] train batch 1188 / 1562 (iter 2750), current average result {'loss': tensor(27.2472, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.0139, device='cuda:0')}
2019-11-25 22:12:19,563 [MainThread  ] Experiment Exp-1
2019-11-25 22:12:19,573 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:12:19,574 [MainThread  ] Start creating tasks
2019-11-25 22:12:19,574 [MainThread  ] Start loading data
2019-11-25 22:12:19,574 [MainThread  ] Loading cifar10_un data
2019-11-25 22:12:27,169 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:12:29,381 [MainThread  ] Start creating models
2019-11-25 22:12:33,484 [MainThread  ] Experiment Exp-1
2019-11-25 22:12:33,496 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:12:33,496 [MainThread  ] Start creating tasks
2019-11-25 22:12:33,497 [MainThread  ] Start loading data
2019-11-25 22:12:33,497 [MainThread  ] Loading cifar10_un data
2019-11-25 22:12:34,191 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:12:34,193 [MainThread  ] Start training cifar10_un
2019-11-25 22:21:52,472 [MainThread  ] train batch 250 / 1562 (iter 250), current average result {'jigsaw_acc': tensor(0.4247, device='cuda:0'), 'loss': tensor(0.6931, device='cuda:0', grad_fn=<DivBackward0>)}
2019-11-25 22:32:37,352 [MainThread  ] Experiment Exp-1
2019-11-25 22:32:37,354 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:32:37,354 [MainThread  ] Start creating tasks
2019-11-25 22:32:37,354 [MainThread  ] Start loading data
2019-11-25 22:32:37,354 [MainThread  ] Loading cifar10_un data
2019-11-25 22:32:44,739 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:32:46,947 [MainThread  ] Start creating models
2019-11-25 22:32:50,541 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:32:50,541 [MainThread  ] Start training cifar10_un
2019-11-25 22:41:34,917 [MainThread  ] Experiment Exp-1
2019-11-25 22:41:34,918 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:41:34,918 [MainThread  ] Start creating tasks
2019-11-25 22:41:34,918 [MainThread  ] Start loading data
2019-11-25 22:41:34,918 [MainThread  ] Loading cifar10_un data
2019-11-25 22:41:42,055 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:41:44,250 [MainThread  ] Start creating models
2019-11-25 22:41:47,892 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:41:47,892 [MainThread  ] Start training cifar10_un
2019-11-25 22:52:49,319 [MainThread  ] Experiment Exp-1
2019-11-25 22:52:49,335 [MainThread  ] Receive config Namespace(batch_size=64, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:52:49,335 [MainThread  ] Start creating tasks
2019-11-25 22:52:49,335 [MainThread  ] Start loading data
2019-11-25 22:52:49,335 [MainThread  ] Loading cifar10_un data
2019-11-25 22:52:56,476 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:52:58,669 [MainThread  ] Start creating models
2019-11-25 22:53:02,258 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:53:02,259 [MainThread  ] Start training cifar10_un
2019-11-25 22:54:46,353 [MainThread  ] Experiment Exp-1
2019-11-25 22:54:46,354 [MainThread  ] Receive config Namespace(batch_size=56, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:54:46,354 [MainThread  ] Start creating tasks
2019-11-25 22:54:46,354 [MainThread  ] Start loading data
2019-11-25 22:54:46,354 [MainThread  ] Loading cifar10_un data
2019-11-25 22:54:53,549 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:54:55,845 [MainThread  ] Start creating models
2019-11-25 22:54:59,440 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:54:59,441 [MainThread  ] Start training cifar10_un
2019-11-25 22:56:32,233 [MainThread  ] Experiment Exp-1
2019-11-25 22:56:32,234 [MainThread  ] Receive config Namespace(batch_size=32, cache_neg=0, clip=0.5, data_dir='./data', device='cuda:0', dup_pos=0, exp_dir='./results/Exp-1', exp_name='Exp-1', finetune_ckpt_interval=0, finetune_tasks=['cifar10_lp5'], finetune_total_iters=10000, finetune_val_interval=2000, finetune_weight_decay=0.01, finetuning_learning_rate=0.0001, load_ckpt='', model='Exp', num_aug=8, num_patches=16, num_queries=4, num_workers=16, pretrain_ckpt_interval=0, pretrain_learning_rate=0.0003, pretrain_task=['cifar10_un'], pretrain_total_iters=100000, pretrain_weight_decay=0.01, report_interval=250, results_dir='./results', transfer_paradigm='frozen', warmup_iters=1000)
2019-11-25 22:56:32,234 [MainThread  ] Start creating tasks
2019-11-25 22:56:32,234 [MainThread  ] Start loading data
2019-11-25 22:56:32,234 [MainThread  ] Loading cifar10_un data
2019-11-25 22:56:39,683 [MainThread  ] Loading cifar10_lp5 data
2019-11-25 22:56:41,891 [MainThread  ] Start creating models
2019-11-25 22:56:45,508 [MainThread  ] Setup trainer for cifar10_un
2019-11-25 22:56:45,508 [MainThread  ] Start training cifar10_un
2019-11-25 23:01:53,863 [MainThread  ] train batch 250 / 3125 (iter 250), current average result {'loss': tensor(0.8975, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4025, device='cuda:0')}
2019-11-25 23:06:59,853 [MainThread  ] train batch 500 / 3125 (iter 500), current average result {'loss': tensor(0.8231, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3094, device='cuda:0')}
2019-11-25 23:12:05,659 [MainThread  ] train batch 750 / 3125 (iter 750), current average result {'loss': tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.2190, device='cuda:0')}
2019-11-25 23:17:11,581 [MainThread  ] train batch 1000 / 3125 (iter 1000), current average result {'loss': tensor(0.8586, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.2604, device='cuda:0')}
2019-11-25 23:22:17,941 [MainThread  ] train batch 1250 / 3125 (iter 1250), current average result {'loss': tensor(0.8435, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.2946, device='cuda:0')}
2019-11-25 23:27:24,307 [MainThread  ] train batch 1500 / 3125 (iter 1500), current average result {'loss': tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3188, device='cuda:0')}
2019-11-25 23:32:30,597 [MainThread  ] train batch 1750 / 3125 (iter 1750), current average result {'loss': tensor(0.8063, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3398, device='cuda:0')}
2019-11-25 23:37:36,696 [MainThread  ] train batch 2000 / 3125 (iter 2000), current average result {'loss': tensor(0.7930, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3570, device='cuda:0')}
2019-11-25 23:42:42,423 [MainThread  ] train batch 2250 / 3125 (iter 2250), current average result {'loss': tensor(0.7823, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3715, device='cuda:0')}
2019-11-25 23:47:48,303 [MainThread  ] train batch 2500 / 3125 (iter 2500), current average result {'loss': tensor(0.7736, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3829, device='cuda:0')}
2019-11-25 23:52:54,060 [MainThread  ] train batch 2750 / 3125 (iter 2750), current average result {'loss': tensor(0.7665, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.3924, device='cuda:0')}
2019-11-25 23:57:59,670 [MainThread  ] train batch 3000 / 3125 (iter 3000), current average result {'loss': tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4006, device='cuda:0')}
2019-11-26 00:03:07,533 [MainThread  ] train batch 125 / 3125 (iter 3250), current average result {'loss': tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4079, device='cuda:0')}
2019-11-26 00:08:12,928 [MainThread  ] train batch 375 / 3125 (iter 3500), current average result {'loss': tensor(0.7509, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4141, device='cuda:0')}
2019-11-26 00:13:18,367 [MainThread  ] train batch 625 / 3125 (iter 3750), current average result {'loss': tensor(0.7470, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4196, device='cuda:0')}
2019-11-26 00:18:24,204 [MainThread  ] train batch 875 / 3125 (iter 4000), current average result {'loss': tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4243, device='cuda:0')}
2019-11-26 00:23:29,972 [MainThread  ] train batch 1125 / 3125 (iter 4250), current average result {'loss': tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4286, device='cuda:0')}
2019-11-26 00:28:35,898 [MainThread  ] train batch 1375 / 3125 (iter 4500), current average result {'loss': tensor(0.7380, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4324, device='cuda:0')}
2019-11-26 00:33:42,114 [MainThread  ] train batch 1625 / 3125 (iter 4750), current average result {'loss': tensor(0.7357, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4353, device='cuda:0')}
2019-11-26 00:38:48,216 [MainThread  ] train batch 1875 / 3125 (iter 5000), current average result {'loss': tensor(0.7335, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4382, device='cuda:0')}
2019-11-26 00:43:54,453 [MainThread  ] train batch 2125 / 3125 (iter 5250), current average result {'loss': tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4406, device='cuda:0')}
2019-11-26 00:49:00,504 [MainThread  ] train batch 2375 / 3125 (iter 5500), current average result {'loss': tensor(0.7299, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4429, device='cuda:0')}
2019-11-26 00:54:06,600 [MainThread  ] train batch 2625 / 3125 (iter 5750), current average result {'loss': tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4450, device='cuda:0')}
2019-11-26 00:59:12,596 [MainThread  ] train batch 2875 / 3125 (iter 6000), current average result {'loss': tensor(0.7268, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4469, device='cuda:0')}
2019-11-26 01:04:18,630 [MainThread  ] train batch 3125 / 3125 (iter 6250), current average result {'loss': tensor(0.7254, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4483, device='cuda:0')}
2019-11-26 01:09:27,516 [MainThread  ] train batch 250 / 3125 (iter 6500), current average result {'loss': tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4459, device='cuda:0')}
2019-11-26 01:14:33,935 [MainThread  ] train batch 500 / 3125 (iter 6750), current average result {'loss': tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4447, device='cuda:0')}
2019-11-26 01:19:40,222 [MainThread  ] train batch 750 / 3125 (iter 7000), current average result {'loss': tensor(0.7221, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4443, device='cuda:0')}
2019-11-26 01:24:46,547 [MainThread  ] train batch 1000 / 3125 (iter 7250), current average result {'loss': tensor(0.7211, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4442, device='cuda:0')}
2019-11-26 01:29:52,790 [MainThread  ] train batch 1250 / 3125 (iter 7500), current average result {'loss': tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4443, device='cuda:0')}
2019-11-26 01:34:59,044 [MainThread  ] train batch 1500 / 3125 (iter 7750), current average result {'loss': tensor(0.7193, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4444, device='cuda:0')}
2019-11-26 01:40:05,157 [MainThread  ] train batch 1750 / 3125 (iter 8000), current average result {'loss': tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4446, device='cuda:0')}
2019-11-26 01:45:11,217 [MainThread  ] train batch 2000 / 3125 (iter 8250), current average result {'loss': tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4448, device='cuda:0')}
2019-11-26 01:50:17,551 [MainThread  ] train batch 2250 / 3125 (iter 8500), current average result {'loss': tensor(0.7170, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4451, device='cuda:0')}
2019-11-26 01:55:23,542 [MainThread  ] train batch 2500 / 3125 (iter 8750), current average result {'loss': tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4453, device='cuda:0')}
2019-11-26 02:00:29,524 [MainThread  ] train batch 2750 / 3125 (iter 9000), current average result {'loss': tensor(0.7157, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4456, device='cuda:0')}
2019-11-26 02:05:35,604 [MainThread  ] train batch 3000 / 3125 (iter 9250), current average result {'loss': tensor(0.7151, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4459, device='cuda:0')}
2019-11-26 02:10:45,845 [MainThread  ] train batch 125 / 3125 (iter 9500), current average result {'loss': tensor(0.7145, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4462, device='cuda:0')}
2019-11-26 02:15:51,942 [MainThread  ] train batch 375 / 3125 (iter 9750), current average result {'loss': tensor(0.7140, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4465, device='cuda:0')}
2019-11-26 02:20:58,061 [MainThread  ] train batch 625 / 3125 (iter 10000), current average result {'loss': tensor(0.7135, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4467, device='cuda:0')}
2019-11-26 02:26:04,464 [MainThread  ] train batch 875 / 3125 (iter 10250), current average result {'loss': tensor(0.7130, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4470, device='cuda:0')}
2019-11-26 02:31:10,424 [MainThread  ] train batch 1125 / 3125 (iter 10500), current average result {'loss': tensor(0.7125, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4473, device='cuda:0')}
2019-11-26 02:36:16,921 [MainThread  ] train batch 1375 / 3125 (iter 10750), current average result {'loss': tensor(0.7120, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4476, device='cuda:0')}
2019-11-26 02:41:23,383 [MainThread  ] train batch 1625 / 3125 (iter 11000), current average result {'loss': tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4479, device='cuda:0')}
2019-11-26 02:46:29,604 [MainThread  ] train batch 1875 / 3125 (iter 11250), current average result {'loss': tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4481, device='cuda:0')}
2019-11-26 02:51:35,880 [MainThread  ] train batch 2125 / 3125 (iter 11500), current average result {'loss': tensor(0.7108, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4484, device='cuda:0')}
2019-11-26 02:56:41,953 [MainThread  ] train batch 2375 / 3125 (iter 11750), current average result {'loss': tensor(0.7104, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4486, device='cuda:0')}
2019-11-26 03:01:47,503 [MainThread  ] train batch 2625 / 3125 (iter 12000), current average result {'loss': tensor(0.7101, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4489, device='cuda:0')}
2019-11-26 03:06:53,156 [MainThread  ] train batch 2875 / 3125 (iter 12250), current average result {'loss': tensor(0.7097, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4492, device='cuda:0')}
2019-11-26 03:11:59,662 [MainThread  ] train batch 3125 / 3125 (iter 12500), current average result {'loss': tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4496, device='cuda:0')}
2019-11-26 03:17:10,038 [MainThread  ] train batch 250 / 3125 (iter 12750), current average result {'loss': tensor(0.7091, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4500, device='cuda:0')}
2019-11-26 03:22:16,333 [MainThread  ] train batch 500 / 3125 (iter 13000), current average result {'loss': tensor(0.7088, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4504, device='cuda:0')}
2019-11-26 03:27:22,276 [MainThread  ] train batch 750 / 3125 (iter 13250), current average result {'loss': tensor(0.7085, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4507, device='cuda:0')}
2019-11-26 03:32:28,741 [MainThread  ] train batch 1000 / 3125 (iter 13500), current average result {'loss': tensor(0.7082, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4512, device='cuda:0')}
2019-11-26 03:37:35,104 [MainThread  ] train batch 1250 / 3125 (iter 13750), current average result {'loss': tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4516, device='cuda:0')}
2019-11-26 03:42:41,694 [MainThread  ] train batch 1500 / 3125 (iter 14000), current average result {'loss': tensor(0.7077, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4521, device='cuda:0')}
2019-11-26 03:47:47,831 [MainThread  ] train batch 1750 / 3125 (iter 14250), current average result {'loss': tensor(0.7074, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4525, device='cuda:0')}
2019-11-26 03:52:54,231 [MainThread  ] train batch 2000 / 3125 (iter 14500), current average result {'loss': tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4529, device='cuda:0')}
2019-11-26 03:58:00,599 [MainThread  ] train batch 2250 / 3125 (iter 14750), current average result {'loss': tensor(0.7070, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4534, device='cuda:0')}
2019-11-26 04:03:06,793 [MainThread  ] train batch 2500 / 3125 (iter 15000), current average result {'loss': tensor(0.7067, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4539, device='cuda:0')}
2019-11-26 04:08:13,008 [MainThread  ] train batch 2750 / 3125 (iter 15250), current average result {'loss': tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4544, device='cuda:0')}
2019-11-26 04:13:19,163 [MainThread  ] train batch 3000 / 3125 (iter 15500), current average result {'loss': tensor(0.7063, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4549, device='cuda:0')}
2019-11-26 04:18:30,082 [MainThread  ] train batch 125 / 3125 (iter 15750), current average result {'loss': tensor(0.7061, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4554, device='cuda:0')}
2019-11-26 04:23:36,361 [MainThread  ] train batch 375 / 3125 (iter 16000), current average result {'loss': tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4559, device='cuda:0')}
2019-11-26 04:28:42,585 [MainThread  ] train batch 625 / 3125 (iter 16250), current average result {'loss': tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4564, device='cuda:0')}
2019-11-26 04:33:49,068 [MainThread  ] train batch 875 / 3125 (iter 16500), current average result {'loss': tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4569, device='cuda:0')}
2019-11-26 04:38:55,742 [MainThread  ] train batch 1125 / 3125 (iter 16750), current average result {'loss': tensor(0.7053, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4574, device='cuda:0')}
2019-11-26 04:44:02,291 [MainThread  ] train batch 1375 / 3125 (iter 17000), current average result {'loss': tensor(0.7052, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4579, device='cuda:0')}
2019-11-26 04:49:08,685 [MainThread  ] train batch 1625 / 3125 (iter 17250), current average result {'loss': tensor(0.7050, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4584, device='cuda:0')}
2019-11-26 04:54:15,019 [MainThread  ] train batch 1875 / 3125 (iter 17500), current average result {'loss': tensor(0.7048, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4589, device='cuda:0')}
2019-11-26 04:59:21,339 [MainThread  ] train batch 2125 / 3125 (iter 17750), current average result {'loss': tensor(0.7047, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4594, device='cuda:0')}
2019-11-26 05:04:27,730 [MainThread  ] train batch 2375 / 3125 (iter 18000), current average result {'loss': tensor(0.7045, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4599, device='cuda:0')}
2019-11-26 05:09:34,144 [MainThread  ] train batch 2625 / 3125 (iter 18250), current average result {'loss': tensor(0.7043, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4604, device='cuda:0')}
2019-11-26 05:14:40,516 [MainThread  ] train batch 2875 / 3125 (iter 18500), current average result {'loss': tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4609, device='cuda:0')}
2019-11-26 05:19:46,756 [MainThread  ] train batch 3125 / 3125 (iter 18750), current average result {'loss': tensor(0.7041, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4614, device='cuda:0')}
2019-11-26 05:24:59,498 [MainThread  ] train batch 250 / 3125 (iter 19000), current average result {'loss': tensor(0.7039, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4619, device='cuda:0')}
2019-11-26 05:30:05,873 [MainThread  ] train batch 500 / 3125 (iter 19250), current average result {'loss': tensor(0.7038, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4624, device='cuda:0')}
2019-11-26 05:35:12,294 [MainThread  ] train batch 750 / 3125 (iter 19500), current average result {'loss': tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4629, device='cuda:0')}
2019-11-26 05:40:18,821 [MainThread  ] train batch 1000 / 3125 (iter 19750), current average result {'loss': tensor(0.7035, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4634, device='cuda:0')}
2019-11-26 05:45:25,265 [MainThread  ] train batch 1250 / 3125 (iter 20000), current average result {'loss': tensor(0.7034, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4638, device='cuda:0')}
2019-11-26 05:50:31,560 [MainThread  ] train batch 1500 / 3125 (iter 20250), current average result {'loss': tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4643, device='cuda:0')}
2019-11-26 05:55:37,823 [MainThread  ] train batch 1750 / 3125 (iter 20500), current average result {'loss': tensor(0.7031, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4647, device='cuda:0')}
2019-11-26 06:00:44,437 [MainThread  ] train batch 2000 / 3125 (iter 20750), current average result {'loss': tensor(0.7030, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4652, device='cuda:0')}
2019-11-26 06:05:51,066 [MainThread  ] train batch 2250 / 3125 (iter 21000), current average result {'loss': tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4656, device='cuda:0')}
2019-11-26 06:10:57,519 [MainThread  ] train batch 2500 / 3125 (iter 21250), current average result {'loss': tensor(0.7028, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4661, device='cuda:0')}
2019-11-26 06:16:03,755 [MainThread  ] train batch 2750 / 3125 (iter 21500), current average result {'loss': tensor(0.7027, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4665, device='cuda:0')}
2019-11-26 06:21:10,537 [MainThread  ] train batch 3000 / 3125 (iter 21750), current average result {'loss': tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4669, device='cuda:0')}
2019-11-26 06:26:22,303 [MainThread  ] train batch 125 / 3125 (iter 22000), current average result {'loss': tensor(0.7025, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4673, device='cuda:0')}
2019-11-26 06:31:28,925 [MainThread  ] train batch 375 / 3125 (iter 22250), current average result {'loss': tensor(0.7024, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4677, device='cuda:0')}
2019-11-26 06:36:35,330 [MainThread  ] train batch 625 / 3125 (iter 22500), current average result {'loss': tensor(0.7023, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4681, device='cuda:0')}
2019-11-26 06:41:42,044 [MainThread  ] train batch 875 / 3125 (iter 22750), current average result {'loss': tensor(0.7022, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4685, device='cuda:0')}
2019-11-26 06:46:48,779 [MainThread  ] train batch 1125 / 3125 (iter 23000), current average result {'loss': tensor(0.7021, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4689, device='cuda:0')}
2019-11-26 06:51:55,197 [MainThread  ] train batch 1375 / 3125 (iter 23250), current average result {'loss': tensor(0.7020, device='cuda:0', grad_fn=<DivBackward0>), 'jigsaw_acc': tensor(0.4693, device='cuda:0')}
